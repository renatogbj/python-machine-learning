{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[3,1], [2,5], [1,8], [6,4], [5,2], [3,5], [4,7], [4,-1]])\n",
    "y = [0, 1, 1, 0, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = np.array([X[i] for i in range(len(X)) if y[i]==0])\n",
    "class_1 = np.array([X[i] for i in range(len(X)) if y[i]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(class_0[:,0], class_0[:,1], color='black', marker='s')\n",
    "plt.scatter(class_1[:,0], class_1[:,1], color='black', marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_x = range(10)\n",
    "line_y = line_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(class_0[:,0], class_0[:,1], color='black', marker='s')\n",
    "plt.scatter(class_1[:,0], class_1[:,1], color='black', marker='x')\n",
    "plt.plot(line_x, line_y, color='black', linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[4, 7], [3.5, 8], [3.1, 6.2], [0.5, 1], [1, 2], [1.2, 1.9], [6, 2], [5.7, 1.5], [5.4, 2.2]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression(solver='liblinear', C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classifier(classifier, X, y):\n",
    "    # define ranges to plot the figure\n",
    "    x_min, x_max = min(X[:, 0]) - 1.0, max(X[:, 0]) + 1.0\n",
    "    y_min, y_max = min(X[:, 1]) - 1.0, max(X[:, 1]) + 1.0\n",
    "    \n",
    "    # denotes the step size that will be used in the mesh grid\n",
    "    step_size = 0.01\n",
    "    \n",
    "    # define the mesh grid\n",
    "    x_values, y_values = np.meshgrid(np.arange(x_min, x_max, step_size), np.arange(y_min, y_max, step_size))\n",
    "    \n",
    "    # compute the classifier output\n",
    "    mesh_output = classifier.predict(np.c_[x_values.ravel(), y_values.ravel()])\n",
    "    \n",
    "    # reshape the array\n",
    "    mesh_output = mesh_output.reshape(x_values.shape)\n",
    "    \n",
    "    # plot the output using a colored plot\n",
    "    plt.figure()\n",
    "    \n",
    "    # choose a color scheme\n",
    "    plt.pcolormesh(x_values, y_values, mesh_output, cmap=plt.cm.gray)\n",
    "    \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=80, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)\n",
    "    \n",
    "    # specify the boundaries of the figure\n",
    "    plt.xlim(x_values.min(), x_values.max())\n",
    "    plt.ylim(y_values.min(), y_values.max())\n",
    "    \n",
    "    # specify the ticks on the X and Y axes\n",
    "    plt.xticks((np.arange(int(min(X[:, 0])-1), int(max(X[:, 0])+1), 1.0)))\n",
    "    plt.yticks((np.arange(int(min(X[:, 1])-1), int(max(X[:, 1])+1), 1.0)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classifier(classifier, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression(solver='liblinear', C=1.0)\n",
    "classifier.fit(X, y)\n",
    "plot_classifier(classifier, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = linear_model.LogisticRegression(solver='liblinear', C=10000)\n",
    "classifier.fit(X, y)\n",
    "plot_classifier(classifier, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'datasets/data_multivar.txt'\n",
    "\n",
    "X, y = [], []\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        data = [float(x) for x in line.split(',')]\n",
    "        X.append(data[:-1])\n",
    "        y.append(data[-1])\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gaussiannb = GaussianNB()\n",
    "classifier_gaussiannb.fit(X, y)\n",
    "y_pred = classifier_gaussiannb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 100.0 * (y == y_pred).sum() / X.shape[0]\n",
    "print(\"Accuracy of the classifier =\", round(accuracy, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classifier(classifier_gaussiannb, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=5)\n",
    "classifier_gaussiannb_new = GaussianNB()\n",
    "classifier_gaussiannb_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = classifier_gaussiannb_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 100.0 * (y_test == y_test_pred).sum() / X_test.shape[0]\n",
    "print(\"Accuracy of the classifier =\", round(accuracy, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classifier(classifier_gaussiannb_new, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the accuracy using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validations = 5\n",
    "accuracy = model_selection.cross_val_score(classifier_gaussiannb, X, y, scoring='accuracy', cv=num_validations)\n",
    "print(\"Accuracy: \" + str(round(100*accuracy.mean(), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = model_selection.cross_val_score(classifier_gaussiannb, X, y, scoring='f1_weighted', cv=num_validations)\n",
    "print(\"F1: \" + str(round(100*f1.mean(), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = model_selection.cross_val_score(classifier_gaussiannb, X, y, scoring='precision_weighted', cv=num_validations)\n",
    "print(\"Precision: \" + str(round(100*precision.mean(), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall = model_selection.cross_val_score(classifier_gaussiannb, X, y, scoring='recall_weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "def plot_confusion_matrix(confusion_mat):\n",
    "    plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.Paired)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(4)\n",
    "    plt.xticks(tick_marks, tick_marks)\n",
    "    plt.yticks(tick_marks, tick_marks)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 0, 0, 2, 1, 0, 3, 3, 3]\n",
    "y_pred = [1, 1, 0, 2, 1, 0, 1, 3, 3]\n",
    "confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the performance report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 0, 0, 2, 1, 0, 3, 3, 3]\n",
    "y_pred = [1, 1, 0, 2, 1, 0, 1, 3, 3]\n",
    "target_names = ['Class-0', 'Class-1', 'Class-2', 'Class-3']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating cars based on their characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'datasets/car.data'\n",
    "\n",
    "# Reading the data\n",
    "X = []\n",
    "count = 0\n",
    "\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        data = line[:-1].split(',')\n",
    "        X.append(data)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string data to numerical data\n",
    "label_encoder = []\n",
    "X_encoded = np.empty(X.shape)\n",
    "for i,item in enumerate(X[0]):\n",
    "    label_encoder.append(preprocessing.LabelEncoder())\n",
    "    X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])\n",
    "\n",
    "X = X_encoded[:, :-1].astype(int)\n",
    "y = X_encoded[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Random Forest classifier\n",
    "params = {'n_estimators': 200, 'max_depth': 8, 'random_state': 7}\n",
    "classifier = RandomForestClassifier(**params)\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_selection.cross_val_score(classifier, X, y, scoring='accuracy', cv=3)\n",
    "print(\"Accuracy of the classifier: \", str(round(100*accuracy.mean(), 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curves\n",
    "from sklearn.model_selection import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(max_depth=4, random_state=7)\n",
    "parameter_grid = np.linspace(25, 200, 8).astype(int)\n",
    "train_scores, validation_scores = validation_curve(classifier, X, y, \"n_estimators\", parameter_grid, cv=5)\n",
    "print(\"##### VALIDATION CURVES #####\")\n",
    "print(\"Param: n_estimators\\nTraining scores:\\n\", train_scores)\n",
    "print(\"Param: n_estimators\\nValidation scores:\\n\", validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the curve\n",
    "plt.figure()\n",
    "plt.plot(parameter_grid, 100*np.average(train_scores, axis=1), color='black')\n",
    "plt.title('Training curve')\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=20, random_state=7)\n",
    "parameter_grid = np.linspace(2, 10, 5).astype(int)\n",
    "train_scores, valid_scores = validation_curve(classifier, X, y, \"max_depth\", parameter_grid, cv=5)\n",
    "print(\"Param: max_depth\\nTraining scores:\\n\", train_scores)\n",
    "print(\"Param: max_depth\\nValidation scores:\\n\", validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(parameter_grid, 100*np.average(train_scores, axis=1), color='black')\n",
    "plt.title('Validation curve')\n",
    "plt.xlabel('Maximum depth of the tree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
